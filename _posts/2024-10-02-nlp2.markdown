---
layout: post
title:  "NLP 3주차"
published: true
date:   2024-10-02 
categories:
    - Data Science
    - NLP
tags: KHUDA NLP
---
# 다층퍼셉트론
- 이전에는 빅그램 모델을 사용해 한 문자의 이전 문자를 기반으로 다음 문자의 분포를 예측했다.
- 한 문자의 컨텍스트만 사용한 모델은 예측력이 낮았다. 그래서 더 많은 컨텍스트를 사용하려 하자 테이블의 크기가 기하급수적으로 증가했다.
- 이를 해결하기 위해 베응이오(Bengio) 등의 연구를 기반으로 다층 퍼셉트론 모델을 적용하려고 계획했다.
- 논문의 방법론은 단어를 30차원 공간에 임베딩하는 것이다. 이 과정에서 17,000개의 단어를 벡터 공간에 매핑한다.
- 이러한 방법은 초기 단계에서 단어를 랜덤하게 초기화하며, 이후 학습을 통해 개선된다.
# 신경망을 위한 데이터셋과 준비 과정
- 이전 영상에서도 보았듯이, 각 로짓(logit)을 지수화한 후, 모든 값을 정규화하여 다음 단어에 대한 확률 분포를 형성한다.
- 훈련 중에는 다음 단어의 정체성을 알 수 있으며, 이를 통해 해당 단어의 확률을 추출하고 최대화하는 과정이 이루어진다.
- 이 과정에서 출력층, 숨겨진 층의 가중치 및 편향, 그리고 임베딩 조회 테이블의 매개변수를 최적화하여 백 프로퍼게이션 방법을 사용한다.
- 이제 새로운 노트북을 시작하고, PyTorch와 Matplotlib을 임포트하여 도표를 생성할 준비를 한다.
- 이후 32,000개의 이름 중 처음 여덟 개를 리스트로 읽어오고, 문자들의 어휘집과 문자열에서 정수로의 매핑을 구축한다.