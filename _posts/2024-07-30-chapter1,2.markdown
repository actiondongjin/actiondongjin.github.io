---
layout: post
title:  "혼자 공부하는 머신러닝+딥러닝 Chapter 1"
published: true
date:   2024-07-30 
categories:
    - Data Science
    - 혼자 공부하는 머신러닝+딥러닝
tags: KHUDA ML
---
# 1. 나의 첫 머신러닝
## 1-1. 인공지능과 머신러닝, 딥러닝
### 인공지능(artificial intelligence)이란
사람처럼 학습하고 추론할 수 있는 지능을 가진 컴퓨터 시스템을 만드는 기술
> 인공지능의 종류
>- 인공일반지능(artificial general intelligence)/강인공지능(Strong AI)\
: **사람과 구분하기 어려운** 지능을 가진 컴퓨터 시스템
>
>- 약인공지능(Week AI)\
: 특정 분야에서 사람의 일을 도와주는 **보조 역할**을 하는 컴퓨터 시스템

### 머신러닝(machine learning)이란
규칙을 일일이 프로그래밍하지 않아도 **자동으로 데이터에서 규칙을 학습하는 알고리즘**을 연구하는 분야

인공지능의 하위 분야 중에서 **지능을 구현하기 위한 소프트웨어**를 담당하는 핵심 분야
> 컴퓨터 과학분야의 대표적인 머신러닝 라이브러리 [사이킷런(scikit-learn)](https://scikit-learn.org/stable/)

### 딥러닝(deep learning)이란
많은 머신러닝 알고리즘 중 **인공 신경망**을 기반으로 한 방법들

> 인공신경망이 이전과 다르게 놀라운 성능을 달성하게 된 원동력 3가지
>- 복잡한 알고리즘을 훈련할 수 있는 풍부한 데이터
>- 컴퓨터 성능의 향상
>- 혁신적인 알고리즘 개발

>딥러닝 라이브러리
>- [텐서플로(TensorFlow)](https://www.tensorflow.org/)\
구글이 오픈소스로 공개한 딥러닝 라이브러리
>
>- [파이토치(PyTorch)](https://pytorch.org/)\
페이스북이 오픈소스로 공개한 딥러닝 라이브러리

## 1-2. 코랩과 주피터 노트북
### 구글 코랩(Colab)
**웹 브라우저**에서 무료로 파이썬 프로그램을 테스트하고 저장할 수 있는 서비스

**클라우드 기반**의 주피터 노트북 개발 환경

머신러닝은 컴퓨터 사양이 중요한데, 구글 코랩을 사용하면 컴퓨터 성능과 상관없이 실습 가능
### 텍스트 셀(cell)
코랩에서 실행할 수 있는 **최소 단위**

셀 안에있는 내용을 한 번에 실행하고 그 결과를 노트북에 표현

### 코드 셀
코드 셀로 이동하면 코드와 결과가 함께 선택
```python
seconds_in_a_day = 24*60*60
seconds_in_a_day
```
`86400`


### 노트북(Notebook)
대화식 프로그래밍 환경인 주피터(Jupyter) 프로젝트의 대표 제품

코드, 코드의 실행 결과, 문서를 모두 저장하여 보관 가능
## 1-3. 마켓과 머신러닝
### 생선 분류 문제
한빛 마켓에서 팔기 시작한 생선은 '도미', '곤들매기', '농어', '강꼬치고기', '로치', '빙어', '송어'

이 생선들을 프로그램으로 분류하는 방법

- 생선 길이가 30cm 이상이면 도미
```python
if fish_length >= 30:
   print("도미")
```

#### 도미 데이터 준비하기
- 생선의 길이 : bream_length

- 생선의 무게 : bream_weight
```python
bream_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 
                31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 
                35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0]
bream_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 
                500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 
                700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0]
```
맷플롯립 패키지를 임포트하고 산점도를 그리는 scatter() 함수를 사용
>- 산점도(scatter plot)\
> : x, y축으로 이뤄진 좌표계에 두 변수(x, y)의 관계를 표현하는 방법 
>- 맷플롯립(matplotlib)\
> : 파이썬에서 과학계산용 그래프를 그리는 대표적인 패키지
>- 임포트(import)\
> : 따로 만둘어둔 파이썬 패키지(함수 묶음)을 사용하기 위해 불러오는 명령\

```python
import matplotlib.pyplot as plt # matplotlib의 pyplot 함수를 plt로 줄여서 사용

plt.scatter(bream_length, bream_weight)
plt.xlabel('length') # x축은 길이
plt.ylabel('weight') # y축은 무게
plt.show()
```
![도미 산점도](/assets/img/산점도.png)

#### 빙어 데이터 준비하기
```python
smelt_length = [9.8, 10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0]
smelt_weight = [6.7, 7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9]
```
```python
plt.scatter(bream_length, bream_weight)
plt.scatter(smelt_length, smelt_weight)
plt.xlabel('length')
plt.ylabel('weight')
plt.show()
```
![도미+ 빙어 산점도](/assets/img/산점도2.png)
### 첫 번째 머신러닝 프로그램
**k-최근접 이웃 알고리즘**(**k-Nearest Neighbors**)을 사용해 도미와 빙어 데이터 구분
```python
length = bream_length + smelt_leght
weight = bream_weight + smelt_weight
```
zip() 함수와 리스트 내포 구문을 사용해 length와 weight 리스트를 2차원 리스트로 만들기
```python
fish_data = [[l,w] for l, w in zip(length,weight)]
```
fish_data가 예상대로 만들어졌는지 출력해서 확인
```python
print(fish_data)
```
```python
[[25.4, 242.0], [26.3, 290.0], [26.5, 340.0], [29.0, 363.0], [29.0, 430.0],
 [29.7, 450.0], [29.7, 500.0], [30.0, 390.0], [30.0, 450.0], [30.7, 500.0],
 [31.0, 475.0], [31.0, 500.0], [31.5, 500.0], [32.0, 340.0], [32.0, 600.0],
 [32.0, 600.0], [33.0, 700.0], [33.0, 700.0], [33.5, 610.0], [33.5, 650.0],
 [34.0, 575.0], [34.0, 685.0], [34.5, 620.0], [35.0, 680.0], [35.0, 700.0],
 [35.0, 725.0], [35.0, 720.0], [36.0, 714.0], [36.0, 850.0], [37.0, 1000.0],
 [38.5, 920.0], [38.5, 955.0], [39.5, 925.0], [41.0, 975.0], [41.0, 950.0],
 [9.8, 6.7], [10.5, 7.5], [10.6, 7.0], [11.0, 9.7], [11.2, 9.8], [11.3, 8.7],
 [11.8, 10.0], [11.8, 9.9], [12.0, 9.8], [12.2, 12.2], [12.4, 13.4],
 [13.0, 12.2], [14.3, 19.7], [15.0, 19.9]]
```
도미와 빙어를 숫자 1과 0으로 표현
```python
fish_target = [1] * 35 + [0] * 14
print(fish_target)
```
```python
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
```
이제 사이킷런 패키지에서 k-최근접 이웃 알고리즘을 구현한 클래스인 KNeighborClassifier를 임포트
```python
from sklearn.neighbors import KNeighborsClassifier
```
임포트한 KNeighborClassifier 클래스의 객체 만들기
```python
kn = KNeighborsClassifier()
```
이 객체에 fish_data와 fish_target을 전달하여 도미를 찾기 위한 기준을 학습시키기
> 머신러닝에서 이런 과정을 **훈련**(**training**)이라고 지칭\
```python
kn.fit(fish_data, fish_target)
```
객체 kn이 얼마나 잘 훈련되었는지 평가하기
```python
kn.score(fish_data, fish_target)
```
```1.0```
